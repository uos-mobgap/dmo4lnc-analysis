{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b0c37fd-c44f-48c9-bb21-fefa7b991289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vedo import Points, Plotter, Line, Axes, Plane, Grid, Sphere, Text2D, shapes\n",
    "import sys\n",
    "from IPython.display import Video\n",
    "import imageio.v2 as imageio\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.io import savemat, loadmat\n",
    "import scipy.io as spio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71be625-9662-4f06-8041-e8ac9c3de29f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_video_from_raw_data(file_name, raw_data_folder, prints = False):\n",
    "\n",
    "    if not prints:\n",
    "        print(\"Generating video...\")\n",
    "        print(\"May take a while: use prints = True to see progress...\")\n",
    "    \n",
    "    # Load data\n",
    "    marker_data = pd.read_table(raw_data_folder+file_name+\".tsv\", \n",
    "                        sep = '\\t',\n",
    "                        skiprows = range(0, 11)\n",
    "                        )\n",
    "    \n",
    "    marker_data = marker_data.drop(marker_data.columns[marker_data.columns.str.contains('unnamed', case=False)], axis=1)\n",
    "    \n",
    "    marker_start_time = pd.read_table(raw_data_folder+file_name+\".tsv\",\n",
    "                                      skiprows = [*range(0, 7), 8], \n",
    "                                      header=None,\n",
    "                                      on_bad_lines = 'skip').to_numpy()\n",
    "\n",
    "    print(marker_start_time)\n",
    "    \n",
    "    marker_start_time = datetime.strptime(marker_start_time[:, 1][0], '%Y-%m-%d, %H:%M:%S.%f').timestamp() # add an hour for daylight savings and some adjustment\n",
    "    \n",
    "    marker_data_np = marker_data.drop([\"Time\", \"Frame\"], axis=1).to_numpy()\n",
    "    \n",
    "    reshaped = marker_data_np.reshape(marker_data_np.shape[0], -1, 3)\n",
    "    reshaped[:, :, [1, 2]] = reshaped[:, :, [2, 1]]\n",
    "    marker_data_np = reshaped.reshape(marker_data_np.shape)\n",
    "\n",
    "    if prints:\n",
    "        print(f\"Raw data shape: {marker_data_np.shape}\")\n",
    "        print()\n",
    "    \n",
    "    # Calculate number of points per frame (each point has 3 coords: x,y,z)\n",
    "    num_points = marker_data_np.shape[1] // 3\n",
    "    \n",
    "    # If folder exists, delete it completely\n",
    "    if os.path.exists(\"output\"):\n",
    "        shutil.rmtree(\"output\")\n",
    "    \n",
    "    # Create empty folder\n",
    "    os.makedirs(\"output\")\n",
    "    \n",
    "    # Initialize Vedo Plotter\n",
    "    vp = Plotter(offscreen=True, bg='white', size=(800, 608))\n",
    "    \n",
    "    # Set camera view\n",
    "    vp.camera.SetPosition(8, 8, 8)\n",
    "    vp.camera.SetFocalPoint(0, 0, 0)\n",
    "    vp.camera.SetViewUp(0, 1, 0)\n",
    "    vp.render()\n",
    "    \n",
    "    grid = Grid(pos=(0,0,0), s=(100,100), res=(200,200), c='lightgray', alpha=0.3)\n",
    "    grid.rotate(angle=90, axis=(1,0,0))  # rotate 90 degrees around X axis\n",
    "    vp.add(grid)\n",
    "    \n",
    "    # format column names for selection\n",
    "    point_names = marker_data.columns.to_list()\n",
    "    point_names = [x for x in point_names if x[-1] not in [\"Y\", \"Z\"]]\n",
    "    point_names.remove(\"Time\")\n",
    "    point_names.remove(\"Frame\")\n",
    "    point_names = [x[:-2] for x in point_names]\n",
    "\n",
    "    connections = [\n",
    "        # hip\n",
    "        (point_names.index('BACK_REF'), point_names.index('BACK_X')),\n",
    "        (point_names.index('BACK_X'), point_names.index('BACK_O')),\n",
    "        (point_names.index('BACK_O'), point_names.index('BACK_Y')),\n",
    "        #right foot\n",
    "        (point_names.index('R_TOE'), point_names.index('R_MET5')),\n",
    "        (point_names.index('R_TOE'), point_names.index('R_HEEL')),\n",
    "        (point_names.index('R_TOE'), point_names.index('R_REF')),\n",
    "        (point_names.index('R_REF'), point_names.index('R_MET5')),\n",
    "        (point_names.index('R_REF'), point_names.index('R_HEEL')),\n",
    "        (point_names.index('R_MET5'), point_names.index('R_HEEL')),\n",
    "        #left foot\n",
    "        (point_names.index('L_TOE'), point_names.index('L_MET5')),\n",
    "        (point_names.index('L_TOE'), point_names.index('L_HEEL')),\n",
    "        (point_names.index('L_TOE'), point_names.index('L_REF')),\n",
    "        (point_names.index('L_REF'), point_names.index('L_MET5')),\n",
    "        (point_names.index('L_REF'), point_names.index('L_HEEL')),\n",
    "        (point_names.index('L_MET5'), point_names.index('L_HEEL')),\n",
    "        #wrist    \n",
    "        (point_names.index('WRIST'), point_names.index('WRIST_LAT')),\n",
    "        (point_names.index('WRIST_MED'), point_names.index('WRIST_LAT')),\n",
    "    ]\n",
    "\n",
    "    # list to hold things to be deleted\n",
    "    dynamic_actors = []\n",
    "    \n",
    "    # Animation loop\n",
    "    for i, frame in enumerate(marker_data_np):\n",
    "        pts_coords = frame.reshape((num_points, 3)) / 1000 # convert from mm to m\n",
    "\n",
    "        if prints:\n",
    "            print(f\"Frame {i}, points shape: {pts_coords.shape}, first point: {pts_coords[0]}\")\n",
    "    \n",
    "        # Remove previous dynamic actors\n",
    "        for actor in dynamic_actors:\n",
    "            vp.remove(actor)\n",
    "        dynamic_actors.clear()\n",
    "    \n",
    "        # Create points and lines\n",
    "        pts = Points(pts_coords, r=3, c='blue')\n",
    "    \n",
    "        for idx1, idx2 in connections:\n",
    "            p1 = pts_coords[idx1]\n",
    "            p2 = pts_coords[idx2]\n",
    "        \n",
    "            if not(np.allclose(p1, 0)) and not(np.allclose(p2, 0)):\n",
    "                line = Line(p1, p2, c='black', lw=2)\n",
    "                vp.add(line)\n",
    "                dynamic_actors.append(line)\n",
    "            else:\n",
    "                # Optionally: log skipped lines\n",
    "                if prints:\n",
    "                    print(f\"Skipping line between {idx1} and {idx2} due to missing data\")\n",
    "    \n",
    "        # Add to scene\n",
    "        vp.add(pts, line)\n",
    "        dynamic_actors.extend([pts, line])\n",
    "    \n",
    "        # Render and save frame\n",
    "        vp.render()\n",
    "        vp.screenshot(f\"output/frame_{i:04d}.png\")\n",
    "    \n",
    "    # Finalize\n",
    "    vp.close()\n",
    "\n",
    "    # Create video from saved frames\n",
    "    image_folder = \"output\"\n",
    "    fps = 100  # frames per second\n",
    "    \n",
    "    images = sorted([img for img in os.listdir(image_folder) if img.endswith(\".png\")])\n",
    "    with imageio.get_writer(raw_data_folder+file_name+\".mp4\", fps=fps) as writer:\n",
    "        for filename in images:\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            image = imageio.imread(image_path)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    print(f\"Video saved to {raw_data_folder+file_name+\".mp4\"}\")\n",
    "    print()\n",
    "    \n",
    "    # get rid of outputs folder\n",
    "    if os.path.exists(\"output\"):\n",
    "        shutil.rmtree(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492d305d-8e5b-4055-8035-20666172fd21",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\ac4jmi\\\\Desktop\\\\DMO4LNC\\\\Data Collection\\\\Dataset\\\\CP\\\\718\\\\Lab\\\\Motion Capture Data\\\\\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m raw_data_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mac4jmi\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDMO4LNC\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData Collection\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m718\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLab\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMotion Capture Data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m tsv_files \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(f)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(raw_data_folder)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynced\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m ]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m tsv_files:\n\u001b[0;32m     10\u001b[0m     generate_video_from_raw_data(file_name, raw_data_folder, prints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\ac4jmi\\\\Desktop\\\\DMO4LNC\\\\Data Collection\\\\Dataset\\\\CP\\\\718\\\\Lab\\\\Motion Capture Data\\\\\\\\'"
     ]
    }
   ],
   "source": [
    "raw_data_folder = r\"C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\Data Collection\\Dataset\\CP\\718\\Lab\\Motion Capture Data\\\\\"\n",
    "\n",
    "tsv_files = [\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir(raw_data_folder)\n",
    "    if f.endswith('.tsv') and not f.startswith('synced')\n",
    "]\n",
    "\n",
    "for file_name in tsv_files:\n",
    "    generate_video_from_raw_data(file_name, raw_data_folder, prints = False)\n",
    "    Video(raw_data_folder+file_name+\".mp4\", embed=True, width=608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc2cea15-5f9e-4336-a773-95977dd37edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadmat from scipy.io imports as a numpy array beyond the first layer, this modified version imports it as an actual dictionary\n",
    "# taken from stack overflow\n",
    "def loadmat_fixed(filename):\n",
    "    data = loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(d):\n",
    "    for key in d:\n",
    "        d[key] = _check_element(d[key])\n",
    "    return d\n",
    "\n",
    "def _check_element(elem):\n",
    "    if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "        return _todict(elem)\n",
    "    elif isinstance(elem, np.ndarray):\n",
    "        return _tolist(elem)\n",
    "    else:\n",
    "        return elem\n",
    "\n",
    "def _todict(matobj):\n",
    "    d = {}\n",
    "    for fieldname in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[fieldname]\n",
    "        d[fieldname] = _check_element(elem)\n",
    "    return d\n",
    "\n",
    "def _tolist(ndarray):\n",
    "    lst = []\n",
    "    for sub_elem in ndarray:\n",
    "        lst.append(_check_element(sub_elem))\n",
    "    return lst\n",
    "\n",
    "def get_plottable_data(data_mat):\n",
    "    # get markers\n",
    "    markers = pd.DataFrame()\n",
    "    for marker in data_mat[\"Standards\"][\"Stereophoto_raw\"][\"Mrks\"].keys():\n",
    "        temp_df = pd.DataFrame(data = data_mat[\"Standards\"][\"Stereophoto_raw\"][\"Mrks\"][marker], columns = [marker+\"_X\", marker+\"_Y\", marker+\"_Z\"])\n",
    "        markers = pd.concat([markers, temp_df], axis=1)\n",
    "\n",
    "    # get imu data\n",
    "    waist_imu_data = pd.DataFrame(data_mat[\"SU\"][\"LowerBack\"][\"Acc\"], columns = [\"Acc_X\", \"Acc_Y\", \"Acc_Z\"])\n",
    "    \n",
    "    # get ic and fc events\n",
    "    # check if we have more than 1 walking bouts\n",
    "    if len(data_mat[\"Standards\"][\"Stereophoto\"][\"ContinuousWalkingPeriod\"]) > 60:\n",
    "        ics = data_mat[\"Standards\"][\"Stereophoto\"][\"ContinuousWalkingPeriod\"][\"InitialContact_Event\"]\n",
    "    else:\n",
    "        ics = []\n",
    "        for cwp in data_mat[\"Standards\"][\"Stereophoto\"][\"ContinuousWalkingPeriod\"]:\n",
    "            ics.extend(cwp[\"InitialContact_Event\"])\n",
    "\n",
    "    \n",
    "    # get time and normalise\n",
    "    t_0 = data_mat[\"SU\"][\"LowerBack\"][\"Timestamp\"][0]\n",
    "    timestamp = pd.DataFrame(data_mat[\"SU\"][\"LowerBack\"][\"Timestamp\"] - t_0, columns=[\"time\"])\n",
    "    \n",
    "    ic_indices = []\n",
    "    \n",
    "    for ic in ics:\n",
    "        # Find the index of the timestamp closest to the event\n",
    "        idx = (timestamp[\"time\"] - ic).abs().idxmin()\n",
    "        ic_indices.append(idx)\n",
    "    \n",
    "    return markers, waist_imu_data, timestamp, ic_indices\n",
    "\n",
    "def generate_mobgap_mocap_videos(data_mat_path):\n",
    "    data_mat_path_full = os.path.join(data_mat_path, \"data.mat\")\n",
    "    print(f\"Loading data from {data_mat_path_full}\")\n",
    "    data_mat = loadmat_fixed(data_mat_path_full)\n",
    "    for test in data_mat[\"data\"][\"TimeMeasure1\"].keys():\n",
    "        # skip standing\n",
    "        if test == \"Test1\":\n",
    "            continue\n",
    "        for trial in data_mat[\"data\"][\"TimeMeasure1\"][test].keys():\n",
    "            marker_data, waist_imu_data, timestamps, ic_indices = get_plottable_data(data_mat[\"data\"][\"TimeMeasure1\"][test][trial])\n",
    "            \n",
    "            filename = f\"{test}_{trial}.mp4\"\n",
    "            save_full_path = os.path.join(data_mat_path, filename)\n",
    "            \n",
    "            vis = MotionVisualizer(marker_data, waist_imu_data, timestamps, ic_indices)\n",
    "            \n",
    "            # Pass the path to start()\n",
    "            vis.start(save_path=save_full_path)\n",
    "            \n",
    "            # To save video (requires modifying run_animation as mentioned above):\n",
    "            # vis.start(save_path=f\"{test}_{trial}.mp4\")\n",
    "            \n",
    "            #print(markers)\n",
    "            #print(waist_imu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7eca71fc-95ef-4843-9617-d6c071efe618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vedo\n",
    "from vedo import Plotter, Sphere, Lines, Video, Grid\n",
    "\n",
    "# Force VTK backend for Jupyter\n",
    "vedo.settings.default_backend = 'vtk' \n",
    "\n",
    "class MotionVisualizer:\n",
    "    def __init__(self, markers_df, imu_df, time_df, ic_indices):\n",
    "        self.markers_df = markers_df\n",
    "        self.imu_df = imu_df\n",
    "        self.time_df = time_df\n",
    "        self.ic_indices = ic_indices\n",
    "        \n",
    "        # 1. Parse Data & Units\n",
    "        self.times = time_df[\"time\"].values\n",
    "        raw_m = markers_df.values\n",
    "        n_frames = raw_m.shape[0]\n",
    "        n_cols = raw_m.shape[1]\n",
    "        \n",
    "        self.marker_pos = raw_m.reshape(n_frames, n_cols // 3, 3)\n",
    "        \n",
    "        # FIX: Swap Y/Z (Y=Up) and convert mm -> m\n",
    "        self.marker_pos[:, :, [1, 2]] = self.marker_pos[:, :, [2, 1]]\n",
    "        self.marker_pos = self.marker_pos / 1000.0\n",
    "        self.n_frames = n_frames\n",
    "        \n",
    "        # 2. Extract Marker Names and Indices\n",
    "        # We assume columns are \"NAME_X\", \"NAME_Y\", \"NAME_Z\"\n",
    "        # So we take every 3rd column and strip the last 2 chars (\"_X\")\n",
    "        all_cols = markers_df.columns.tolist()\n",
    "        marker_names = [c[:-2] for c in all_cols[0::3]]\n",
    "        \n",
    "        # --- UPDATED CONNECTIONS TO MATCH YOUR DATAFRAME ---\n",
    "        target_connections = [\n",
    "            # Hip / Back (Updated names: BACKREF, BACKX, BACK0, BACKY)\n",
    "            ('BACKREF', 'BACKX'), \n",
    "            ('BACKX', 'BACK0'), \n",
    "            ('BACK0', 'BACKY'),\n",
    "            \n",
    "            # Right Foot (Updated names: RTOE, RMET5, RHEEL, RREF)\n",
    "            ('RTOE', 'RMET5'), \n",
    "            ('RTOE', 'RHEEL'), \n",
    "            ('RTOE', 'RREF'),\n",
    "            ('RREF', 'RMET5'), \n",
    "            ('RREF', 'RHEEL'), \n",
    "            ('RMET5', 'RHEEL'),\n",
    "            \n",
    "            # Left Foot (Assuming similar naming: LTOE, LMET5, LHEEL, LREF)\n",
    "            ('LTOE', 'LMET5'), \n",
    "            ('LTOE', 'LHEEL'), \n",
    "            ('LTOE', 'LREF'),\n",
    "            ('LREF', 'LMET5'), \n",
    "            ('LREF', 'LHEEL'), \n",
    "            ('LMET5', 'LHEEL'),\n",
    "            \n",
    "            # Wrist (Assuming WRIST, WRISTLAT, WRISTMED based on typical sets)\n",
    "            ('WRIST', 'WRISTLAT'), \n",
    "            ('WRISTMED', 'WRISTLAT')\n",
    "        ]\n",
    "        \n",
    "        self.conn_indices = []\n",
    "        for name1, name2 in target_connections:\n",
    "            try:\n",
    "                idx1 = marker_names.index(name1)\n",
    "                idx2 = marker_names.index(name2)\n",
    "                self.conn_indices.append((idx1, idx2))\n",
    "            except ValueError:\n",
    "                # print(f\"Warning: Connection {name1}-{name2} skipped (markers not found)\")\n",
    "                pass\n",
    "\n",
    "        # 3. Setup Plotter\n",
    "        self.plt = Plotter(shape=(2, 1), sharecam=False, size=(800, 1000), offscreen=True, bg='white')\n",
    "\n",
    "    def start(self, save_path=\"output.mp4\"):\n",
    "        if save_path is None: save_path = \"output.mp4\"\n",
    "        print(f\"Setting up scenes for: {save_path}\")\n",
    "        \n",
    "        # --- TOP VIEWPORT: MOCAP ---\n",
    "        self.plt.at(0)\n",
    "        \n",
    "        # Floor Grid\n",
    "        grid = Grid(pos=(0,0,0), s=(40, 40), res=(40, 40), c='lightgray', alpha=0.3)\n",
    "        grid.rotate(angle=90, axis=(1, 0, 0))\n",
    "        self.plt += grid\n",
    "        \n",
    "        # Initial Points\n",
    "        initial_coords = self.marker_pos[0]\n",
    "        self.mocap_points = []\n",
    "        \n",
    "        for i in range(len(initial_coords)):\n",
    "            s = Sphere(pos=initial_coords[i], r=0.015, c=\"blue\") \n",
    "            self.mocap_points.append(s)\n",
    "            self.plt += s\n",
    "            \n",
    "        self.skeleton_lines = None \n",
    "        \n",
    "        # Initialize Camera (Position will be updated in loop)\n",
    "        cam0 = self.plt.at(0).camera\n",
    "        cam0.SetViewUp(0, 1, 0)\n",
    "        cam0.SetPosition(8, 8, 8)\n",
    "        cam0.SetFocalPoint(0, 0, 0)\n",
    "\n",
    "        # --- BOTTOM VIEWPORT: IMU ---\n",
    "        self.plt.at(1)\n",
    "        self.plt += vedo.Text2D(\"IMU Acceleration\", pos=\"top-left\", c=\"black\")\n",
    "        \n",
    "        z_zeros = np.zeros_like(self.times)\n",
    "        pts_x = np.column_stack((self.times, self.imu_df[\"Acc_X\"].values, z_zeros))\n",
    "        pts_y = np.column_stack((self.times, self.imu_df[\"Acc_Y\"].values, z_zeros))\n",
    "        pts_z = np.column_stack((self.times, self.imu_df[\"Acc_Z\"].values, z_zeros))\n",
    "        \n",
    "        self.plt += [\n",
    "            vedo.Line(pts_x, c=\"red\", lw=2),\n",
    "            vedo.Line(pts_y, c=\"green\", lw=2),\n",
    "            vedo.Line(pts_z, c=\"blue\", lw=2)\n",
    "        ]\n",
    "        \n",
    "        y_min = self.imu_df.min().min()\n",
    "        y_max = self.imu_df.max().max()\n",
    "        \n",
    "        for idx in self.ic_indices:\n",
    "            if idx < len(self.times):\n",
    "                t = self.times[idx]\n",
    "                self.plt += vedo.Line([(t, y_min, 0), (t, y_max, 0)], c=\"black\", lw=2, alpha=0.5)\n",
    "\n",
    "        self.cursor = vedo.Line([(0, y_min, 0), (0, y_max, 0)], c=\"gold\", lw=4)\n",
    "        self.plt += self.cursor\n",
    "\n",
    "        cam1 = self.plt.at(1).camera\n",
    "        cam1.SetParallelProjection(True)\n",
    "        \n",
    "        self.run_animation(save_path)\n",
    "\n",
    "    def run_animation(self, save_path):\n",
    "        y_center = (self.imu_df.max().max() + self.imu_df.min().min()) / 2\n",
    "        y_range = self.imu_df.max().max() - self.imu_df.min().min()\n",
    "        \n",
    "        video = Video(save_path, backend='cv2', fps=50)\n",
    "        step = 2\n",
    "        \n",
    "        print(f\"Processing {self.n_frames} frames...\")\n",
    "        \n",
    "        # Camera tracking offset (X, Y, Z) meters relative to subject\n",
    "        camera_offset = np.array([5.0, 3.0, 5.0]) \n",
    "        \n",
    "        for idx in range(0, self.n_frames, step): \n",
    "            if idx % 50 == 0: print(f\"Frame {idx}/{self.n_frames}\", end='\\r')\n",
    "\n",
    "            # --- UPDATE MOCAP ---\n",
    "            current_pos = self.marker_pos[idx]\n",
    "            \n",
    "            # 1. Update Points & Calculate Center\n",
    "            valid_points = []\n",
    "            for i, actor in enumerate(self.mocap_points):\n",
    "                p = current_pos[i]\n",
    "                actor.pos(p)\n",
    "                if not np.allclose(p, 0):\n",
    "                    valid_points.append(p)\n",
    "            \n",
    "            # 2. Update Lines\n",
    "            valid_starts, valid_ends = [], []\n",
    "            for i1, i2 in self.conn_indices:\n",
    "                p1, p2 = current_pos[i1], current_pos[i2]\n",
    "                if not (np.allclose(p1, 0) or np.allclose(p2, 0)):\n",
    "                    valid_starts.append(p1)\n",
    "                    valid_ends.append(p2)\n",
    "            \n",
    "            if self.skeleton_lines: self.plt.at(0).remove(self.skeleton_lines)\n",
    "            if valid_starts:\n",
    "                self.skeleton_lines = Lines(valid_starts, valid_ends, c='black', lw=2)\n",
    "                self.plt.at(0).add(self.skeleton_lines)\n",
    "\n",
    "            # 3. Update Camera Tracking\n",
    "            if valid_points:\n",
    "                center_of_mass = np.mean(valid_points, axis=0)\n",
    "                cam0 = self.plt.at(0).camera\n",
    "                cam0.SetFocalPoint(center_of_mass)\n",
    "                cam0.SetPosition(center_of_mass + camera_offset)\n",
    "                cam0.SetViewUp(0, 1, 0)\n",
    "\n",
    "            # --- UPDATE IMU ---\n",
    "            t = self.times[idx]\n",
    "            self.cursor.x(t)\n",
    "            cam = self.plt.at(1).camera\n",
    "            cam.SetFocalPoint(t, y_center, 0)\n",
    "            cam.SetPosition(t, y_center, 10)\n",
    "            cam.SetParallelScale(y_range * 0.6) \n",
    "\n",
    "            self.plt.render()\n",
    "            video.add_frame()\n",
    "\n",
    "        video.close()\n",
    "        self.plt.close()\n",
    "        print(f\"\\nSaved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d88d32f-194d-43c4-a0bd-23bc96a10b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\data.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ac4jmi\\AppData\\Local\\Temp\\ipykernel_39384\\1210194949.py:13: DeprecationWarning: Please import `mat_struct` from the `scipy.io.matlab` namespace; the `scipy.io.matlab.mio5_params` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up scenes for: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test2_Trial1.mp4\n",
      "Processing 1647 frames...:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test2_Trial1.mp4 is open... \u001b[0m\n",
      "Frame 1600/1647\n",
      "Saved: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test2_Trial1.mp4\n",
      "Setting up scenes for: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test3_Trial1.mp4\n",
      "Processing 1933 frames...:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test3_Trial1.mp4 is open... \u001b[0m\n",
      "Frame 1900/1933\n",
      "Saved: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test3_Trial1.mp4\n",
      "Setting up scenes for: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test4_Trial1.mp4\n",
      "Processing 4296 frames...:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test4_Trial1.mp4 is open... \u001b[0m\n",
      "Frame 4250/4296\n",
      "Saved: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test4_Trial1.mp4\n",
      "Setting up scenes for: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test5_Trial1.mp4\n",
      "\u001b[1m\u001b[35mðŸ“½  Video file C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test5_Trial1.mp4 is open... \u001b[0mProcessing 2035 frames...\n",
      "Frame 2000/2035\n",
      "Saved: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test5_Trial1.mp4\n",
      "Setting up scenes for: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test6_Trial1.mp4\n",
      "Processing 2341 frames...:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test6_Trial1.mp4 is open... \u001b[0m\n",
      "Frame 2300/2341\n",
      "Saved: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test6_Trial1.mp4\n",
      "Setting up scenes for: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test7_Trial1.mp4\n",
      "\u001b[1m\u001b[35mðŸ“½  Video file C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test7_Trial1.mp4 is open... \u001b[0mProcessing 4061 frames...\n",
      "Frame 4050/4061\n",
      "Saved: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test7_Trial1.mp4\n",
      "Setting up scenes for: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test8_Trial1.mp4\n",
      "\u001b[1m\u001b[35mðŸ“½  Video file C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test8_Trial1.mp4 is open... \u001b[0mProcessing 3758 frames...\n",
      "Frame 3750/3758\n",
      "Saved: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test8_Trial1.mp4\n",
      "Setting up scenes for: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test9_Trial1.mp4\n",
      "\u001b[1m\u001b[35mðŸ“½  Video file C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test9_Trial1.mp4 is open... \u001b[0mProcessing 4097 frames...\n",
      "Frame 4050/4097\n",
      "Saved: C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\\Test9_Trial1.mp4\n"
     ]
    }
   ],
   "source": [
    "data_mat_folder = r\"C:\\Users\\ac4jmi\\Desktop\\DMO4LNC\\dmo4lnc-analysis\\Dataset\\CP\\383\\Lab\\Laboratory\"\n",
    "generate_mobgap_mocap_videos(data_mat_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc356e5d-08c3-4793-afc0-75538eb60f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
